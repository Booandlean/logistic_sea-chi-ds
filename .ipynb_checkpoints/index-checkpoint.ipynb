{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning goals\n",
    "\n",
    "1. Compare predicting a continuous outcome to predicting a class\n",
    "2. Compare linear to logistic regression as classification models\n",
    "3. Understand how the sigmoid function translates the linear equation to a probability\n",
    "4. Describe why logistic regression is a descriminative, parametric algorithm\n",
    "5. Learn how to interpret a trained logistic model's coefficients\n",
    "6. Explore the C (inverse regularization) paramater and hyperparameter tune\n",
    "7. Learn how to adjust the threshold of a logistic model\n",
    "8. Describe the assumptions of linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a good model to usher us into the world of classification. It takes a concept we are familiar with, a linear equation, and translates it into a form fit for predicting a class.  \n",
    "\n",
    "It generally can't compete with the best supervised learning algorithms, but it is simple, fast, and interpretable.  \n",
    "\n",
    "As we will see in mod 4, it will also serve as a segue into our lessons on neural nets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compare predicting a continuous outcome to predicting a class\n",
    "\n",
    "Thus far, we have worked to predict continuous target variables using linear regression. \n",
    "\n",
    "  - Continous target variables:\n",
    "        - Sales price of a home\n",
    "        - MPG of a car\n",
    "        - Price of Google stock\n",
    "        - Number of rides per day on the El\n",
    "        - HS graduation rates\n",
    "        \n",
    "We will now transition into another category of prediction: classification. Instead of continous target variables, we will be predicting whether records from are data are labeled as a particular class.  Whereas the output for the linear regression model can be any number, the output of our classification algorithms can only be a value designated by a set of discrete outcomes.\n",
    "\n",
    "  - Categorical target variables:\n",
    "        - Whether an employee will stay at a company or leave (churn)\n",
    "        - Whether a tumor is cancerous or benign\n",
    "        - Whether a flower is a rose, a dandelion, a tulip, or a daffodil\n",
    "        - Whether a voter is Republican, Democrat, or Independent\n",
    "        \n",
    "What are some other categorical target variables can you think of?\n",
    "\n",
    "![discuss](https://media.giphy.com/media/l0MYIAUWRmVVzfHag/giphy.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are still dealing with **labeled data**.\n",
    "\n",
    "![labels](https://media.giphy.com/media/26Ff5evMweBsENWqk/giphy.gif)\n",
    "\n",
    "\n",
    "This is still supervised learning. \n",
    "\n",
    "But now, instead of the label being a continuous value, such as house price, the label is the category.  This can be either binary or multiclass.  But we still need the labels to train our models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "# Here, in our familiar iris dataset, we see that the target variable is one of three classes labeled 0, 1, 2 \n",
    "# relating to setosa, versicolor, and virginica\n",
    "print(data.target)\n",
    "print(data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compare linear to logistic regression as classification models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of logistic regression, and any classification problem, is to build a model which accurately separates the classes based on independent variables.  \n",
    "\n",
    "We are already familiar with how linear regression finds a best-fit \"line\".  It uses the MSE cost function to minimize the difference between true and predicted values.  \n",
    "\n",
    "A natural thought would be to use that \"line\" to descriminate between classes: Everything with an output greater than a certain point is classified as a 1, everything below is classified as a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glass Data\n",
    "Take the glass data set from the UCI Machine Learning Dataset.  \n",
    "\n",
    "It is composed of a set of features describing the physical makeup of different glass types.  \n",
    "\n",
    "Glass types 1,2,3 represent window glass.\n",
    "Glass types 4,5,6 represent household glass.\n",
    "\n",
    "We will try to predict whether a record is window glass or household glass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "      <th>household</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type  \\\n",
       "id                                                                           \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1   \n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6   \n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1   \n",
       "\n",
       "     household  \n",
       "id              \n",
       "22           0  \n",
       "185          1  \n",
       "40           0  \n",
       "39           0  \n",
       "51           0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glass identification dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'\n",
    "col_names = ['id','ri','na','mg','al','si','k','ca','ba','fe','glass_type']\n",
    "glass = pd.read_csv(url, names=col_names, index_col='id')\n",
    "glass.sort_values('al', inplace=True)\n",
    "# types 1, 2, 3 are window glass\n",
    "# types 5, 6, 7 are household glass\n",
    "glass['household'] = glass.glass_type.map({1:0, 2:0, 3:0, 5:1, 6:1, 7:1})\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the relationship between aluminum content and glass type. \n",
    "There appears to be a relationship between the two, where more aluminum correlates with household glass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'household')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(glass.al, glass.household)\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could fit a linear regression model to this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# fit a linear regression model and store the predictions\n",
    "\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.household\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "glass['household_pred'] = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'household')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot that includes the regression line\n",
    "plt.scatter(glass.al, glass.household)\n",
    "plt.plot(glass.al, glass.household_pred, color='red')\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some issues with the graph above?\n",
    "\n",
    "![talk amongst yourselves](https://media.giphy.com/media/3o6Zt44rlujPePNVVC/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If al=3, what class do we predict for household?\n",
    "\n",
    "If al=1.5, what class do we predict for household?\n",
    "\n",
    "We predict the 0 class for lower values of al, and the 1 class for higher values of al. What's our cutoff value? Around al=2, because that's where the linear regression line crosses the midpoint between predicting class 0 and class 1.\n",
    "\n",
    "Therefore, we'll say that if household_pred >= 0.5, we predict a class of 1, else we predict a class of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "      <th>household</th>\n",
       "      <th>household_pred</th>\n",
       "      <th>household_pred_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.340495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.315436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.250283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.250283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.230236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type  \\\n",
       "id                                                                           \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1   \n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6   \n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1   \n",
       "\n",
       "     household  household_pred  household_pred_class  \n",
       "id                                                    \n",
       "22           0       -0.340495                     0  \n",
       "185          1       -0.315436                     0  \n",
       "40           0       -0.250283                     0  \n",
       "39           0       -0.250283                     0  \n",
       "51           0       -0.230236                     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform household_pred to 1 or 0\n",
    "glass['household_pred_class'] = np.where(glass.household_pred >= 0.5, 1, 0)\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'household')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the class predictions\n",
    "plt.scatter(glass.al, glass.household)\n",
    "plt.plot(glass.al, glass.household_pred_class, color='red')\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what happens if we have class imbalance.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# fit a linear regression model and store the predictions\n",
    "\n",
    "feature_cols = ['al']\n",
    "\n",
    "# Add data with high aluminum content associated with household glass\n",
    "X_more = np.random.normal(4.5, .25, 20)\n",
    "y_more = np.full(20, 1,)\n",
    "y_aug = np.append(y, y_more)\n",
    "X_aug = np.append(X['al'], X_more).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_aug, y_aug.reshape(-1,1))\n",
    "y_hat = lr.predict(X_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'household')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The line is shifts dramatically with this outliers.\n",
    "plt.scatter(X_aug, y_aug)\n",
    "plt.plot(X_aug, y_hat, color='red')\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'household')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With class imbalance\n",
    "\n",
    "pred_class = np.where(y_hat >= 0.5, 1, 0)\n",
    "np.unique(pred_class, return_counts = True)\n",
    "\n",
    "# plot the class predictions\n",
    "plt.scatter(X_aug, y_aug)\n",
    "plt.plot(X_aug, pred_class, color='red')\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about we use logistic logistic regression instead?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression performs a similar function as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a logistic regression model and store the class predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.household\n",
    "logreg.fit(X, y)\n",
    "glass['household_pred_class'] = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'household')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the class predictions\n",
    "plt.scatter(glass.al, glass.household)\n",
    "plt.plot(glass.al, glass.household_pred_class, color='red')\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only do we have class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a logistic regression model and store the class predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "\n",
    "logreg.fit(X_aug, y_aug)\n",
    "log_aug_pred = logreg.predict(X_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'household')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the class predictions\n",
    "plt.scatter(X_aug, y_aug)\n",
    "plt.plot(X_aug, log_aug_pred, color='red')\n",
    "plt.xlabel('al')\n",
    "plt.ylabel('household')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Understand how the sigmoid function translates the linear equation to a probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Proba\n",
    "\n",
    "Let's take a closer look into what fitting the logistic model results in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with the class predictions, we have probabilities associated with each record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99850141, 0.00149859],\n",
       "       [0.99815364, 0.00184636],\n",
       "       [0.99682475, 0.00317525],\n",
       "       [0.99682475, 0.00317525],\n",
       "       [0.99624893, 0.00375107],\n",
       "       [0.99538086, 0.00461914],\n",
       "       [0.99538086, 0.00461914],\n",
       "       [0.99498004, 0.00501996],\n",
       "       [0.99328482, 0.00671518],\n",
       "       [0.99300013, 0.00699987]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities and the sigmoid functions\n",
    "Here, we can start digging deeper into how logistic regression works.\n",
    "\n",
    "The idea behind logistic regression is to model the conditional probability of a class given a set of independent features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the binary case, it is the probability of a 0 or 1 based on a set of independent features X.\n",
    "\n",
    "$\\Large P(G = 1|X = x)$\n",
    "\n",
    "Since the total probability must be equal to 1:\n",
    "\n",
    "$\\Large P(G = 0|X = x) = 1 - P(G = 1|X = x)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to realize such a goal, we have to somehow translate our linear output into a probability.  As we know, probability takes on a value between 0 and 1,  whereas the linear equation can output any value from $-\\infty$ to $\\infty$.\n",
    "\n",
    "![sigmoid](https://media.giphy.com/media/GtKtQ9Gb064uY/giphy.gif)\n",
    "\n",
    "In comes the sigmoid function to the rescue.\n",
    "\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/1600/1*RqXFpiNGwdiKBWyLJc_E7g.png' />\n",
    "\n",
    "If ‘Z’ goes to infinity, Y(predicted) will become 1 and if ‘Z’ goes to negative infinity, Y(predicted) will become 0.\n",
    "\n",
    "\n",
    "\n",
    "Using the sigmoid function above, if X = 1, the estimated probability would be 0.8. This tells that there is 80% chance that this observation would fall in the positive class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(any_number):\n",
    "    \n",
    "    \"Input any number, return a number between 0 and 1\"\n",
    "    \n",
    "    return 1/(1+ np.e**(-any_number))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your head, work through the approximate output of the function for:\n",
    "  - z = 0\n",
    "  - z = 1000\n",
    "  - z = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sigmoid() missing 1 required positional argument: 'any_number'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-32c3939704e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now, input numbers into the function to see that it is functioning correcting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sigmoid() missing 1 required positional argument: 'any_number'"
     ]
    }
   ],
   "source": [
    "# Now, input numbers into the function to see that it is functioning correcting.\n",
    "\n",
    "sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking it to the linear equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part.  The input of the sigmoid is our trusty old linear equation.\n",
    "\n",
    "$$ \\hat y = \\hat\\beta_0 + \\hat\\beta_1 x_1 + \\hat\\beta_2, x_2 +\\ldots + \\hat\\beta_n x_n $$\n",
    "\n",
    "The linear equation is passed into the sigmoid function to produce a probability between 0 and 1\n",
    "$$\\displaystyle\\frac{1}{1+e^{-(\\hat \\beta_o+\\hat \\beta_1 x_1 + \\hat \\beta_2 x_2...\\hat\\beta_n x_n)}}$$\n",
    "\n",
    "Remember, the goal of logistic regression is to model the conditional of a class using a transformation of the linear equation.\n",
    "\n",
    "In other words:\n",
    "\n",
    "$$\\Large P(G = 1|X = x_1, x_2...x_n) = \\frac{1}{1+e^{-(\\hat \\beta_o+\\hat \\beta_1 x_1 + \\hat \\beta_2 x_2...\\hat\\beta_n x_n)}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with some arithmetic:\n",
    "\n",
    "You can show that, by multiplying both numerator and denominator by $e^{(\\hat \\beta_o+\\hat \\beta_1 x_1 + \\hat \\beta_2 x_2...\\hat\\beta_n x_n)}$\n",
    "\n",
    "\n",
    "$$ \\Large P(G = 1|X = x) = \\displaystyle \\frac{e^{\\hat \\beta_o+\\hat \\beta_1 x_1 + \\hat \\beta_2 x_2...\\hat\\beta_n x_n}}{1+e^{\\hat \\beta_o+\\hat \\beta_1 x_1 + \\hat \\beta_2 x_2...\\hat\\beta_n x_n}}$$\n",
    "\n",
    "As a result, you can compute:\n",
    "\n",
    "$$ \\Large P(G = 0|X =x) = 1- \\displaystyle \\frac{e^{\\hat \\beta_o+\\hat \\beta_1 x_1 + \\hat \\beta_2 x_2...\\hat\\beta_n x_n}}{1+e^{\\hat \\beta_o+\\hat \\beta_1 x_1 + \\hat \\beta_2 x_2...\\hat\\beta_n x_n}}= \\displaystyle \\frac{1}{1+e^{\\hat \\beta_o+\\hat \\beta_1 x_1 + \\hat \\beta_2 x_2...\\hat\\beta_n x_n}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odds ratio\n",
    "\n",
    "This doesn't seem to be very spectacular, but combining these two results leads to an easy interpretation of the model parameters, triggered by the *odds*, which equal p/(1-p):\n",
    "\n",
    "$$ \\Large \\dfrac{ P(G = 1|X = x) }{P(G = 0|X =x)} = e^{\\hat \\beta_o+\\hat \\beta_1 x_1 + \\hat \\beta_2 x_2...\\hat\\beta_n x_n} $$\n",
    "\n",
    "This expression can be interpreted as the *odds in favor of class 1*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the log of both sides leads to:\n",
    "<br><br>\n",
    "    $\\ln{\\dfrac{ P(G = 1|X = x) }{P(G = 0|X =x)}} = \\beta_0 + \\beta_1*X_1 + \\beta_2*X_2...\\beta_n*X_n$\n",
    "    \n",
    "Here me can see why we call it logisitic regression.\n",
    "\n",
    "Our linear function calculates the log of the probability we predict 1, divided by the probability of predicting 0.  In other words, the linear equation is calculating the **log of the odds** that we predict a class of 1.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair\n",
    "### Those are a lot of formulas to take in.  \n",
    "\n",
    "To help us reinforce how logistic regression works, let's do an exercise where we reproduce the predicted probabilities by using our coefficients.  Below is model we fit above, predicting whether glass was window or household glass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "      <th>household</th>\n",
       "      <th>household_pred</th>\n",
       "      <th>household_pred_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.340495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.315436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.250283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.250283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.230236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type  \\\n",
       "id                                                                           \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1   \n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6   \n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1   \n",
       "\n",
       "     household  household_pred  household_pred_class  \n",
       "id                                                    \n",
       "22           0       -0.340495                     0  \n",
       "185          1       -0.315436                     0  \n",
       "40           0       -0.250283                     0  \n",
       "39           0       -0.250283                     0  \n",
       "51           0       -0.230236                     0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.household\n",
    "logreg.fit(X, y)\n",
    "glass['household_pred_class'] = logreg.predict(X)\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like linear regression, logistic regression calculates parameters associated with features and intercept. In the fit model above, we have one coefficient associated with aluminum, and one associate with the intercept.\n",
    "\n",
    "In the cell below, use those coefficients along with the original data to calculate an array repressenting the logodds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_odds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "22    -6.501280\n",
       "185   -6.292259\n",
       "40    -5.748805\n",
       "39    -5.748805\n",
       "51    -5.581589\n",
       "184   -5.372568\n",
       "110   -5.372568\n",
       "158   -5.288960\n",
       "153   -4.996331\n",
       "104   -4.954527\n",
       "Name: al, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "log_odds = glass['al']*logreg.coef_[0] + logreg.intercept_\n",
    "log_odds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take that array, and feed it into the sigmoid function to get the probabilities of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0014992652045145013,\n",
       " 0.001847156298978947,\n",
       " 0.0031764633049502795,\n",
       " 0.0031764633049502795,\n",
       " 0.003752442511807795,\n",
       " 0.004620743778464678,\n",
       " 0.004620743778464678,\n",
       " 0.00502166268078726,\n",
       " 0.006717287268443344,\n",
       " 0.007002041892247891]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "p_1 = [sigmoid(log_odd) for log_odd in log_odds ]\n",
    "p_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99850073, 0.00149927],\n",
       "       [0.99815284, 0.00184716],\n",
       "       [0.99682354, 0.00317646],\n",
       "       [0.99682354, 0.00317646],\n",
       "       [0.99624756, 0.00375244],\n",
       "       [0.99537926, 0.00462074],\n",
       "       [0.99537926, 0.00462074],\n",
       "       [0.99497834, 0.00502166],\n",
       "       [0.99328271, 0.00671729],\n",
       "       [0.99299796, 0.00700204]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the output of predict_proba matches the probabilities you calculated\n",
    "logreg.predict_proba(X)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Describe why logistic regression is a descriminative, parametric algorithm\n",
    "\n",
    "\n",
    "A decision boundary is a pretty simple concept. Logistic regression is a classification algorithm, the output should be a category: Yes/No, True/False, Red/Yellow/Orange. Our prediction function however returns a probability score between 0 and 1. A decision boundary is a threshold or tipping point that helps us decide which category to choose based on probability.\n",
    "\n",
    "Logistic regression is a parametric, discriminative model.  \n",
    "\n",
    "In other words, its decisions are made via trained parameters: our beta coefficients. The hyperplane that these coefficients define is a boundary by which we can discriminate between the classes.    \n",
    "\n",
    "![](img/decision_boundary_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Interpreting Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our coefficient calculated above mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.18041341]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** A 1 unit increase in 'al' is associated with a 4.18 unit increase in the log-odds of 'household'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bottom line:** Positive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on optimizing the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of optimizing the coefficients based on mean squared error, logistic regression looks to maximize the likelihood of seeing the probabilities given the class.\n",
    "\n",
    "Because we are dealing with a binary outcome, our likelihood equation comes from the Bernouli distribution:\n",
    "\n",
    "$$ \\Large Likelihood=\\prod\\limits_{i=0}^N p_i^{y_i}(1-p_i)^{1-y_i}$$\n",
    "\n",
    "Taking the log of both sides leads to the log_likelihood equation:\n",
    "\n",
    "$$ \\Large loglikelihood = \\sum\\limits_{i=1}^N y_i\\log{p_i} + (1-y_i)\\log(1-p_i) $$\n",
    "\n",
    "The goal of MLE is to maximize log-likelihood.\n",
    "\n",
    "Or, as we are generally look for minimums, we minimize the negative loglikelihood, which is our cost function:\n",
    "\n",
    "$$ \\Large negative\\ loglikelihood = \\sum\\limits_{i=1}^N - y_i\\log{p_i} - (1-y_i)\\log(1-p_i) $$\n",
    "\n",
    "When solving for the optimal coefficients of a logistic regression model, Log-Loss is the cost function that is used.\n",
    "\n",
    "\n",
    "The general idea is to start with a set of betas, calculate the probabilities, calculate the log-likelihood, adjust the Betas in the direction of which gradient is heading towards higher likelihood.\n",
    "\n",
    "There is no closed form solution like the normal equation in linear regression, so we have to use stocastic gradient descent.  To do so we take the derivative of the negative loglikelihood and set it to zero to find the gradient of the loglikelihood, then update our coefficients. Just like in linear regression SGD, we use a learning rate when updating them.\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a\n",
    "\n",
    "http://wiki.fast.ai/index.php/Log_Loss\n",
    "\n",
    "Here is a good Youtube video on MLE: https://www.youtube.com/watch?v=BfKanl1aSG0\n",
    "\n",
    "Math behind the gradient of log-likelihood is ESL section 4.4.1: https://web.stanford.edu/~hastie/ElemStatLearn//.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Hyperparameter Tuning the C Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have discussed 'L1' (lasso)  and 'L2' (ridge) regularization.  If you looked at the docstring of Sklearn's Logistic Regression function, you may have noticed that we can specify different types of regularization when fitting the model via the `penalty` parameter.\n",
    "\n",
    "We can also specificy the strength of the regularization via the `C` parameter. `C` is the inverse regularization strength.  So, a low `C` means high regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Ridge regularization with low strength\n",
    "logr = LogisticRegression(penalty='l2', C=10**8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.18217114e-01  3.50280937e-02 -1.35333258e-02  7.25847638e-04\n",
      "  -1.20213666e-03  9.05742512e-02  9.52539204e-01  1.60020353e-02]]\n",
      "[-8.42344453]\n",
      "0.7825520833333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmaxbarry/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logr = LogisticRegression(penalty='l2', C=10**8)\n",
    "y = diabetes.Outcome\n",
    "X = diabetes.drop(\"Outcome\", axis=1)\n",
    "logr.fit(X, y)\n",
    "\n",
    "print(logr.coef_)\n",
    "print(logr.intercept_)\n",
    "print(logr.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1232 Pregnancies\n",
      "0.0352 Glucose\n",
      "-0.0133 BloodPressure\n",
      "0.0006 SkinThickness\n",
      "-0.0012 Insulin\n",
      "0.0897 BMI\n",
      "0.9456 DiabetesPedigreeFunction\n",
      "0.0149 Age\n",
      "[-8.40952187]\n",
      "0.7825520833333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmaxbarry/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    }
   ],
   "source": [
    "# Same result as 'none'\n",
    "logr = LogisticRegression(penalty='none', C=10**8, max_iter=10000)\n",
    "y = diabetes.Outcome\n",
    "X = diabetes.drop(\"Outcome\", axis=1)\n",
    "logr.fit(X, y)\n",
    "\n",
    "for coef, feature in zip(list(logr.coef_[0]), X.columns):\n",
    "    print(round(coef,4), feature)\n",
    "print(logr.intercept_)\n",
    "print(logr.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0134 Pregnancies\n",
      "0.0324 Glucose\n",
      "-0.0055 BloodPressure\n",
      "0.006 SkinThickness\n",
      "-0.0008 Insulin\n",
      "0.0313 BMI\n",
      "0.0012 DiabetesPedigreeFunction\n",
      "0.018 Age\n",
      "[-6.02705282]\n",
      "0.7643229166666666\n"
     ]
    }
   ],
   "source": [
    "# With a high L2 regularization, the coefficients shrink.\n",
    "logr = LogisticRegression(penalty='l2', C=.0001)\n",
    "y = diabetes.Outcome\n",
    "X = diabetes.drop(\"Outcome\", axis=1)\n",
    "logr.fit(X, y)\n",
    "\n",
    "for coef, feature in zip(list(logr.coef_[0]), X.columns):\n",
    "    print(round(coef,4), feature)\n",
    "print(logr.intercept_)\n",
    "print(logr.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 Pregnancies\n",
      "0.0 Glucose\n",
      "0.0 BloodPressure\n",
      "0.0 SkinThickness\n",
      "0.0 Insulin\n",
      "0.0 BMI\n",
      "0.0 DiabetesPedigreeFunction\n",
      "0.0 Age\n",
      "[0.]\n",
      "0.6510416666666666\n"
     ]
    }
   ],
   "source": [
    "# try with a strongL1. They are all shrunk to zero!\n",
    "logr = LogisticRegression(penalty='l1', C=.0001, solver='liblinear')\n",
    "y = diabetes.Outcome\n",
    "X = diabetes.drop(\"Outcome\", axis=1)\n",
    "logr.fit(X, y)\n",
    "\n",
    "for coef, feature in zip(list(logr.coef_[0]), X.columns):\n",
    "    print(round(coef,4), feature)\n",
    "print(logr.intercept_)\n",
    "print(logr.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we choose between them? We iterate over possible parameters and judge the success based on our metric of choice.  We will eventually move towards grid search, which will help us be more thorough with our tuning.  For now, we will work through how to tune our C parameter with an Ridge regularization.\n",
    "\n",
    "For now, let's judge on accuracy, which can be accessed via the `score()` method of a trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters for C can be anything above 0.  \n",
    "# Set up a list of possible values to try out.\n",
    "# Start with 1000 numbers above 0\n",
    "c_candidates = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00e-04, 1.00e+00, 2.00e+00, ..., 9.98e+02, 9.99e+02, 1.00e+03])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "# The parameters for C can be anything above 0.  \n",
    "# Set up a list of possible values to try out.\n",
    "# Start with numbers above 0 up to 1000\n",
    "c_candidates = np.linspace(1,1000,1000)\n",
    "c_candidates = np.insert(c_candidates, 0, .0001)\n",
    "c_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training and test data with a random state of 42 \n",
    "# and a test size of .3\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "# Split your data into training and test data with a random state of 42 \n",
    "# and a test size of .3\n",
    "X = diabetes.drop('Outcome', axis=1)\n",
    "y = diabetes.Outcome\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, \n",
    "                                                    test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05806895  0.03587482 -0.0108455  -0.00152413 -0.00099075  0.10902572\n",
      "   0.42182975  0.03594817]]\n",
      "[-9.44606271]\n",
      "0.7359307359307359\n"
     ]
    }
   ],
   "source": [
    "# Train the no regularization logistic model on the train set, \n",
    "# and return the accuracy as measured on the test\n",
    "\n",
    "logr = LogisticRegression(penalty='l2', C=10**8, max_iter=10000)\n",
    "y = diabetes.Outcome\n",
    "X = diabetes.drop(\"Outcome\", axis=1)\n",
    "logr.fit(X_train, y_train)\n",
    "\n",
    "print(logr.coef_)\n",
    "print(logr.intercept_)\n",
    "print(logr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-b7eebe9cade7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbest_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mbest_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Create a for loop which runs through all of the possible values of C,\n",
    "# fits the model on the train set, and scores the model on test set.\n",
    "# Add the accuracies into a dictionary or a list, whichever you prefer\n",
    "# Use 'l2'\n",
    "\n",
    "c_scores = {}\n",
    "for c in c_candidates:\n",
    "    pass\n",
    "\n",
    "best_c = max(c_scores, key=c_scores.get)\n",
    "best_c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "# Create a for loop which runs through all of the possible values of C,\n",
    "# fits the model on the train set, and scores the model on test set.\n",
    "# Add the accuracies into a dictionary or a list, whichever you prefer\n",
    "# Use 'l2'\n",
    "\n",
    "c_scores = {}\n",
    "for c in c_candidates:\n",
    "    regr = LogisticRegression(penalty='l2', C=c, max_iter=10000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    accuracy = regr.score(X_test, y_test)\n",
    "    c_scores[c] = accuracy\n",
    "    \n",
    "# the best accuracy score comes with the highest regularization\n",
    "best_c = max(c_scores, key=c_scores.get)\n",
    "best_c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you have the best C for the range of values between 0 and 1000,\n",
    "# narrow in even further.  Choose a new range of 100 C-values between your best C\n",
    "# and the next closer integer.\n",
    "import math\n",
    "c_candidates = np.linspace(math.floor(best_c)+.01,math.floor(best_c)+1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17 0.7359307359307359\n"
     ]
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "c_scores = {}\n",
    "for c in c_candidates:\n",
    "    regr = LogisticRegression(penalty='l2', C=c, max_iter=10000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    accuracy = regr.score(X_test, y_test)\n",
    "    c_scores[c] = accuracy\n",
    "    \n",
    "# the best accuracy score comes with the highest regularization\n",
    "best_c = max(c_scores, key=c_scores.get)\n",
    "print(best_c, c_scores[best_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved our test R^2 from .740 to .745. Not too much gain. \n",
    "Sometimes hyperparameter tuning can have a large effect, sometimes not. \n",
    "Don't rely on hyperparameter tuning to fix your model.  \n",
    "Treat it as a necessary step in the process which if you are lucky, may increase the predictive power of your model.\n",
    "\n",
    "In future lessons, we will use Grid Search to automate our hyperparamater tuning, and make it more thorough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because logistic regression calculates the probability of a given class, we can easily change the threshold of what is categorized as a 1 or a 0.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our best c from above, and use predict_proba() to output probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73448964, 0.26551036],\n",
       "       [0.81663515, 0.18336485],\n",
       "       [0.87880443, 0.12119557],\n",
       "       [0.84386409, 0.15613591],\n",
       "       [0.50388651, 0.49611349],\n",
       "       [0.55417737, 0.44582263],\n",
       "       [0.98640773, 0.01359227],\n",
       "       [0.38353854, 0.61646146],\n",
       "       [0.44359444, 0.55640556],\n",
       "       [0.20688072, 0.79311928],\n",
       "       [0.77188623, 0.22811377],\n",
       "       [0.09960853, 0.90039147],\n",
       "       [0.61558465, 0.38441535],\n",
       "       [0.71437818, 0.28562182],\n",
       "       [0.93046452, 0.06953548],\n",
       "       [0.64019335, 0.35980665],\n",
       "       [0.87284577, 0.12715423],\n",
       "       [0.93133688, 0.06866312],\n",
       "       [0.14131971, 0.85868029],\n",
       "       [0.40641923, 0.59358077],\n",
       "       [0.78804599, 0.21195401],\n",
       "       [0.92446224, 0.07553776],\n",
       "       [0.52986444, 0.47013556],\n",
       "       [0.90654853, 0.09345147],\n",
       "       [0.4564225 , 0.5435775 ],\n",
       "       [0.11356232, 0.88643768],\n",
       "       [0.89170448, 0.10829552],\n",
       "       [0.96976598, 0.03023402],\n",
       "       [0.72707198, 0.27292802],\n",
       "       [0.8859791 , 0.1140209 ],\n",
       "       [0.08577806, 0.91422194],\n",
       "       [0.11940044, 0.88059956],\n",
       "       [0.19446235, 0.80553765],\n",
       "       [0.17623291, 0.82376709],\n",
       "       [0.3606312 , 0.6393688 ],\n",
       "       [0.31454081, 0.68545919],\n",
       "       [0.0452017 , 0.9547983 ],\n",
       "       [0.77140866, 0.22859134],\n",
       "       [0.51918911, 0.48081089],\n",
       "       [0.27040316, 0.72959684],\n",
       "       [0.93723944, 0.06276056],\n",
       "       [0.41661771, 0.58338229],\n",
       "       [0.44573304, 0.55426696],\n",
       "       [0.68472919, 0.31527081],\n",
       "       [0.97167786, 0.02832214],\n",
       "       [0.47071468, 0.52928532],\n",
       "       [0.3917095 , 0.6082905 ],\n",
       "       [0.79440448, 0.20559552],\n",
       "       [0.66340286, 0.33659714],\n",
       "       [0.03603383, 0.96396617],\n",
       "       [0.95598421, 0.04401579],\n",
       "       [0.34075161, 0.65924839],\n",
       "       [0.17477983, 0.82522017],\n",
       "       [0.74132017, 0.25867983],\n",
       "       [0.8926453 , 0.1073547 ],\n",
       "       [0.96262389, 0.03737611],\n",
       "       [0.20995711, 0.79004289],\n",
       "       [0.99590968, 0.00409032],\n",
       "       [0.59599864, 0.40400136],\n",
       "       [0.2220079 , 0.7779921 ],\n",
       "       [0.27553141, 0.72446859],\n",
       "       [0.65488957, 0.34511043],\n",
       "       [0.77054217, 0.22945783],\n",
       "       [0.7939636 , 0.2060364 ],\n",
       "       [0.9180347 , 0.0819653 ],\n",
       "       [0.38202982, 0.61797018],\n",
       "       [0.95516759, 0.04483241],\n",
       "       [0.21616069, 0.78383931],\n",
       "       [0.96318711, 0.03681289],\n",
       "       [0.21083105, 0.78916895],\n",
       "       [0.3044171 , 0.6955829 ],\n",
       "       [0.93360253, 0.06639747],\n",
       "       [0.83152467, 0.16847533],\n",
       "       [0.88093397, 0.11906603],\n",
       "       [0.91050754, 0.08949246],\n",
       "       [0.49425782, 0.50574218],\n",
       "       [0.8399165 , 0.1600835 ],\n",
       "       [0.88482845, 0.11517155],\n",
       "       [0.86126514, 0.13873486],\n",
       "       [0.73691508, 0.26308492],\n",
       "       [0.33029405, 0.66970595],\n",
       "       [0.86348794, 0.13651206],\n",
       "       [0.94428648, 0.05571352],\n",
       "       [0.59527863, 0.40472137],\n",
       "       [0.73421246, 0.26578754],\n",
       "       [0.13527446, 0.86472554],\n",
       "       [0.09754939, 0.90245061],\n",
       "       [0.68656665, 0.31343335],\n",
       "       [0.88744933, 0.11255067],\n",
       "       [0.91616052, 0.08383948],\n",
       "       [0.9378747 , 0.0621253 ],\n",
       "       [0.7420584 , 0.2579416 ],\n",
       "       [0.99699002, 0.00300998],\n",
       "       [0.49566077, 0.50433923],\n",
       "       [0.47727056, 0.52272944],\n",
       "       [0.35620501, 0.64379499],\n",
       "       [0.64891581, 0.35108419],\n",
       "       [0.8804961 , 0.1195039 ],\n",
       "       [0.31696977, 0.68303023],\n",
       "       [0.92094959, 0.07905041],\n",
       "       [0.27567292, 0.72432708],\n",
       "       [0.93780694, 0.06219306],\n",
       "       [0.20924864, 0.79075136],\n",
       "       [0.46045482, 0.53954518],\n",
       "       [0.33602521, 0.66397479],\n",
       "       [0.76796238, 0.23203762],\n",
       "       [0.75384868, 0.24615132],\n",
       "       [0.25165018, 0.74834982],\n",
       "       [0.88760793, 0.11239207],\n",
       "       [0.51192644, 0.48807356],\n",
       "       [0.91307805, 0.08692195],\n",
       "       [0.64206582, 0.35793418],\n",
       "       [0.98578232, 0.01421768],\n",
       "       [0.22908243, 0.77091757],\n",
       "       [0.81541793, 0.18458207],\n",
       "       [0.68082214, 0.31917786],\n",
       "       [0.24703858, 0.75296142],\n",
       "       [0.77724461, 0.22275539],\n",
       "       [0.93778172, 0.06221828],\n",
       "       [0.45642043, 0.54357957],\n",
       "       [0.94066963, 0.05933037],\n",
       "       [0.73526882, 0.26473118],\n",
       "       [0.78291046, 0.21708954],\n",
       "       [0.9331154 , 0.0668846 ],\n",
       "       [0.71565279, 0.28434721],\n",
       "       [0.6070472 , 0.3929528 ],\n",
       "       [0.97129524, 0.02870476],\n",
       "       [0.13691968, 0.86308032],\n",
       "       [0.03232322, 0.96767678],\n",
       "       [0.25776838, 0.74223162],\n",
       "       [0.29250286, 0.70749714],\n",
       "       [0.14084784, 0.85915216],\n",
       "       [0.9105725 , 0.0894275 ],\n",
       "       [0.58611539, 0.41388461],\n",
       "       [0.161801  , 0.838199  ],\n",
       "       [0.88206124, 0.11793876],\n",
       "       [0.83530604, 0.16469396],\n",
       "       [0.12030205, 0.87969795],\n",
       "       [0.1973698 , 0.8026302 ],\n",
       "       [0.9884428 , 0.0115572 ],\n",
       "       [0.91202144, 0.08797856],\n",
       "       [0.96095232, 0.03904768],\n",
       "       [0.7800487 , 0.2199513 ],\n",
       "       [0.54922969, 0.45077031],\n",
       "       [0.87011032, 0.12988968],\n",
       "       [0.74108079, 0.25891921],\n",
       "       [0.8828019 , 0.1171981 ],\n",
       "       [0.98094143, 0.01905857],\n",
       "       [0.59249147, 0.40750853],\n",
       "       [0.22838805, 0.77161195],\n",
       "       [0.90147561, 0.09852439],\n",
       "       [0.5211832 , 0.4788168 ],\n",
       "       [0.73869919, 0.26130081],\n",
       "       [0.83498853, 0.16501147],\n",
       "       [0.99539938, 0.00460062],\n",
       "       [0.58266239, 0.41733761],\n",
       "       [0.68679347, 0.31320653],\n",
       "       [0.35139478, 0.64860522],\n",
       "       [0.23889093, 0.76110907],\n",
       "       [0.85497748, 0.14502252],\n",
       "       [0.48619602, 0.51380398],\n",
       "       [0.35638455, 0.64361545],\n",
       "       [0.81827383, 0.18172617],\n",
       "       [0.98437037, 0.01562963],\n",
       "       [0.87798117, 0.12201883],\n",
       "       [0.11800231, 0.88199769],\n",
       "       [0.95296749, 0.04703251],\n",
       "       [0.70366246, 0.29633754],\n",
       "       [0.20095442, 0.79904558],\n",
       "       [0.45024235, 0.54975765],\n",
       "       [0.37696556, 0.62303444],\n",
       "       [0.82695131, 0.17304869],\n",
       "       [0.65615804, 0.34384196],\n",
       "       [0.23445147, 0.76554853],\n",
       "       [0.35824207, 0.64175793],\n",
       "       [0.91265245, 0.08734755],\n",
       "       [0.70319609, 0.29680391],\n",
       "       [0.74996434, 0.25003566],\n",
       "       [0.78201433, 0.21798567],\n",
       "       [0.67922025, 0.32077975],\n",
       "       [0.49282494, 0.50717506],\n",
       "       [0.41049691, 0.58950309],\n",
       "       [0.60774864, 0.39225136],\n",
       "       [0.22081729, 0.77918271],\n",
       "       [0.35573603, 0.64426397],\n",
       "       [0.90971712, 0.09028288],\n",
       "       [0.95601041, 0.04398959],\n",
       "       [0.87819494, 0.12180506],\n",
       "       [0.15269383, 0.84730617],\n",
       "       [0.63366366, 0.36633634],\n",
       "       [0.93913987, 0.06086013],\n",
       "       [0.91530767, 0.08469233],\n",
       "       [0.11413536, 0.88586464],\n",
       "       [0.74844187, 0.25155813],\n",
       "       [0.92521747, 0.07478253],\n",
       "       [0.94579229, 0.05420771],\n",
       "       [0.9961893 , 0.0038107 ],\n",
       "       [0.93757734, 0.06242266],\n",
       "       [0.76018382, 0.23981618],\n",
       "       [0.3063606 , 0.6936394 ],\n",
       "       [0.86976076, 0.13023924],\n",
       "       [0.88826324, 0.11173676],\n",
       "       [0.65462468, 0.34537532],\n",
       "       [0.72899025, 0.27100975],\n",
       "       [0.3014781 , 0.6985219 ],\n",
       "       [0.90824438, 0.09175562],\n",
       "       [0.90106051, 0.09893949],\n",
       "       [0.75161894, 0.24838106],\n",
       "       [0.09902713, 0.90097287],\n",
       "       [0.37897441, 0.62102559],\n",
       "       [0.72382684, 0.27617316],\n",
       "       [0.78898929, 0.21101071],\n",
       "       [0.85974489, 0.14025511],\n",
       "       [0.88536914, 0.11463086],\n",
       "       [0.27039747, 0.72960253],\n",
       "       [0.91524768, 0.08475232],\n",
       "       [0.19063715, 0.80936285],\n",
       "       [0.70929191, 0.29070809],\n",
       "       [0.65451459, 0.34548541],\n",
       "       [0.12021553, 0.87978447],\n",
       "       [0.39279522, 0.60720478],\n",
       "       [0.89679068, 0.10320932],\n",
       "       [0.92657739, 0.07342261],\n",
       "       [0.83985673, 0.16014327],\n",
       "       [0.93769284, 0.06230716],\n",
       "       [0.25276423, 0.74723577],\n",
       "       [0.67609522, 0.32390478],\n",
       "       [0.73267162, 0.26732838],\n",
       "       [0.70352636, 0.29647364],\n",
       "       [0.8171564 , 0.1828436 ],\n",
       "       [0.89906029, 0.10093971]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = LogisticRegression(penalty='l2', C=c)\n",
    "regr.fit(X_train, y_train)\n",
    "probas = regr.predict_proba(X_test)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = regr.predict(X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the output of predict and predict proba. Write out below how the output of predict_proba is related to the predict output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The default threshold is .5. Any value in the predict_proba first column above .5 is categorized as a 0. \\nAny value above .5 in the second column is categorized as 1.'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "\"\"\"The default threshold is .5. Any value in the predict_proba first column above .5 is categorized as a 0. \n",
    "Any value above .5 in the second column is categorized as 1.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, isolate one of the columns of predict_proba, and create an area of booleans which returns True if the proba is above .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "lower_threshold = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the astype method to convert the array to integers: True will become 1, and False will become 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "predictions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the accuracy of the model will fall by increasing the threshold, we are protecting against a certain type of error. What type of error are we reducing? Of the metrics that we have learned, what score will increase? Why might protecting against such errors be smart in a model that deals with a life-threatening medical condition?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "# check that logic in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score with default .5 threshold: 0.625\n",
      "Recall score with default .4 threshold: 0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "higher_threshold = probas[:,1] > .7\n",
    "y_hat_lower = higher_threshold.astype(int)\n",
    "\n",
    "\"\"\"By increasing the threshold, we are protecting against false negatives. Our recall score will increase. \n",
    "In the case of heart disease, we should err on the side of caution.  We would rather have a false positive \n",
    "mistake, since the individual would still be flagged for intervention. A false negative could result in death\"\"\"\n",
    "\n",
    "print(f\"Recall score with default .5 threshold: {recall_score(y_hat, y_test)}\")\n",
    "print(f\"Recall score with default .4 threshold: {recall_score(y_hat_lower, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Assumptions of Logistic Regression\n",
    "\n",
    "Logistic regression does not make many of the key assumptions of linear regression and general linear models that are based on ordinary least squares algorithms – particularly regarding linearity, normality, and homoscedasticity.\n",
    "\n",
    "First, logistic regression does not require a linear relationship between the dependent and independent variables.  Second, the error terms (residuals) do not need to be normally distributed.  Third, homoscedasticity is not required.  \n",
    "\n",
    "**The following assumptions still apply:**\n",
    "\n",
    "1.  Binary logistic regression requires the dependent variable to be binary and ordinal logistic regression requires the dependent variable to be ordinal.\n",
    "\n",
    "2. Logistic regression requires the observations to be independent of each other.  In other words, the observations should not come from repeated measurements or matched data.\n",
    "\n",
    "3. Logistic regression requires there to be little or no multicollinearity among the independent variables.  This means that the independent variables should not be too highly correlated with each other.\n",
    "\n",
    "4. Logistic regression assumes linearity of independent variables and log odds.  although this analysis does not require the dependent and independent variables to be related linearly, it requires that the independent variables are linearly related to the log odds.\n",
    "\n",
    "5. Logistic regression typically requires a large sample size.  A general guideline is that you need at minimum of 10 cases with the least frequent outcome for each independent variable in your model. For example, if you have 5 independent variables and the expected probability of your least frequent outcome is .10, then you would need a minimum sample size of 500 (10*5 / .10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
